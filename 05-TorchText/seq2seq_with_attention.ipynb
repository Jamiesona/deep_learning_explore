{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, embed_size, vocab_size, enc_hidden_size, dec_hidden_size):\n",
    "        '''构造方法.\n",
    "        Args:\n",
    "            embed_size: 词向量维度\n",
    "            vocab_size: 词典大小\n",
    "            enc_hidden_size: Encoder的隐藏状态维度\n",
    "            dec_hidden_size: Decoder的隐藏状态维度\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(embed_size, enc_hidden_size)\n",
    "        self.linear = nn.Linear(enc_hidden_size, dec_hidden_size)\n",
    "        \n",
    "    def forward(self, input_seq):\n",
    "        '''前向传播.\n",
    "        Args:\n",
    "            input_seq: 输入序列, shape (N, batch_size)\n",
    "        Returns:\n",
    "            encoder_outputs: 每个时间步的输出(N, batch_size, enc_hidden_size)\n",
    "            last_hidden: 最后一个时间步的输出(1, batch_size, dec_hidden_size)\n",
    "        '''\n",
    "        # 判断是否有batch_size维度\n",
    "        if input_seq.dim() < 2:\n",
    "            input_seq = input_seq.view(-1, 1)\n",
    "        # 保证序列长度至少为2\n",
    "        if len(input_seq) < 2:\n",
    "            input_seq = input_seq.repeat(2, 1)\n",
    "        embed = self.embed(input_seq)\n",
    "        encoder_outputs, last_hidden = self.rnn(embed)\n",
    "        last_hidden = torch.tanh(self.linear(last_hidden))\n",
    "        return encoder_outputs, last_hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "SRC_VOCAB_SIZE = 100\n",
    "TGT_VOCAB_SIZE = 100\n",
    "\n",
    "\n",
    "EMBED_SIZE = 30\n",
    "ENC_HIDDEN_SIZE = 20\n",
    "DEC_HIDDEN_SIZE = 30\n",
    "ATT_SIZE = 15\n",
    "\n",
    "BATCH_SIZE = 30\n",
    "\n",
    "CUDA = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-8db590ef8024>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCUDA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSRC_VOCAB_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCUDA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTGT_VOCAB_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure"
     ]
    }
   ],
   "source": [
    "x = torch.empty(10, 10, BATCH_SIZE, device=CUDA, dtype=torch.long).random_(SRC_VOCAB_SIZE)\n",
    "y = torch.empty(10, 7, BATCH_SIZE, device=CUDA, dtype=torch.long).random_(TGT_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hidden_size, dec_hidden_size, att_size):\n",
    "        '''构造方法.\n",
    "        Args:\n",
    "            enc_hidden_size:\n",
    "            dec_hidden_size:\n",
    "            att_size:\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(enc_hidden_size, att_size)\n",
    "        self.linear_2 = nn.Linear(dec_hidden_size, att_size)\n",
    "        \n",
    "    def forward(self, encoder_outputs, decoder_hidden):\n",
    "        # 首先将二者变换到att_size\n",
    "        query = self.linear_1(encoder_outputs)\n",
    "        key = self.linear_2(decoder_hidden)\n",
    "        scores = torch.softmax((key * query).sum(dim=2), dim=0) #(N, batch_size)\n",
    "        \n",
    "        # (1, batch_size, enc_hidden_size)\n",
    "        weighted_val = (scores.unsqueeze(2) * encoder_outputs).sum(dim=0, keepdim=True)\n",
    "        return weighted_val, scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, embed_size, vocab_size, dec_hidden_size, enc_hidden_size, att_size):\n",
    "        '''构造方法.\n",
    "        Args:\n",
    "            embed_size:\n",
    "            vocab_size:\n",
    "            dec_hidden_size:\n",
    "            enc_hidden_size:\n",
    "            att_size:\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.dec_hidden_size = dec_hidden_size\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(embed_size+enc_hidden_size, dec_hidden_size)\n",
    "        self.att = Attention(enc_hidden_size, dec_hidden_size, att_size)\n",
    "        self.linear = nn.Linear(dec_hidden_size, vocab_size)\n",
    "        \n",
    "    def forward(self, tgt_seq, encoder_outputs, hidden):\n",
    "        # 判断是否有batch_size维度\n",
    "        if tgt_seq.dim() < 2:\n",
    "            tgt_seq = tgt_seq.view(1, -1)\n",
    "        # 保证序列长度至少为2\n",
    "        if len(tgt_seq) < 2:\n",
    "            tgt_seq = tgt_seq.repeat(2, 1)\n",
    "        embed = self.embed(tgt_seq) #(N, batch_size, embed_size)\n",
    "        max_len, batch_size = embed.shape[0], embed.shape[1]\n",
    "        \n",
    "        tgt_seq_hat = torch.zeros(max_len, embed.shape[1], self.dec_hidden_size, device=CUDA)\n",
    "        att_scores = torch.zeros(max_len, encoder_outputs.shape[0], embed.shape[1], device=CUDA)\n",
    "        \n",
    "        for idx in range(1, max_len):\n",
    "            weight_val, scores = self.att(encoder_outputs, hidden) #(1, batch_size, enc_hidden_size)\n",
    "            rnn_input = torch.cat((embed[idx-1:idx], weight_val), dim=2)\n",
    "            decoder_output, hidden = self.rnn(rnn_input, hidden)\n",
    "            tgt_seq_hat[idx] = decoder_output\n",
    "            att_scores[idx] = scores\n",
    "            \n",
    "        tgt_seq_hat = torch.tanh(self.linear(tgt_seq_hat))\n",
    "        return tgt_seq_hat, hidden, att_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, enc:Encoder, dec:Decoder):\n",
    "        super().__init__()\n",
    "        self.enc = enc\n",
    "        self.dec = dec\n",
    "        \n",
    "    def forward(self, src_seq, tgt_seq):\n",
    "        encoder_outputs, last_hidden = self.enc(src_seq)\n",
    "        tgt_seq_hat, _, att_scores = self.dec(tgt_seq, encoder_outputs, last_hidden)\n",
    "        return tgt_seq_hat, att_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-a57797bc5354>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mseq2seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeq2Seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mseq2seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCUDA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure"
     ]
    }
   ],
   "source": [
    "enc = Encoder(EMBED_SIZE, 100, ENC_HIDDEN_SIZE, DEC_HIDDEN_SIZE)\n",
    "dec = Decoder(EMBED_SIZE, 100, DEC_HIDDEN_SIZE, ENC_HIDDEN_SIZE, ATT_SIZE)\n",
    "\n",
    "seq2seq = Seq2Seq(enc, dec)\n",
    "seq2seq.to(CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total train parameters: 21010\n"
     ]
    }
   ],
   "source": [
    "s = sum(p.numel() for p in seq2seq.parameters() if p.requires_grad)\n",
    "print(f'total train parameters: {s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(seq2seq, x, y, epochs=10, lr=0.01):\n",
    "    seq2seq.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    trainer = optim.Adam(seq2seq.parameters(), lr=lr)\n",
    "    # n = len(train_iter)\n",
    "    n = len(x)\n",
    "    losses = torch.zeros(epochs)\n",
    "    for idx in range(epochs):\n",
    "        for xx, yy in zip(x, y):\n",
    "            # xx, yy = batch.src, batch.trg\n",
    "            yy_hat, _ = seq2seq(xx, yy)\n",
    "            yy_hat = yy_hat.transpose(1, 2)\n",
    "            loss = criterion(yy_hat[1:], yy[1:])\n",
    "            loss.backward()\n",
    "            trainer.step()\n",
    "            trainer.zero_grad()\n",
    "            losses[idx] += loss.cpu().detach().item()\n",
    "            \n",
    "    return losses/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = train_model(seq2seq, x, y, 30, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses, 'r--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6838)\n"
     ]
    }
   ],
   "source": [
    "print(losses[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(enc, dec, input_seq, sos_token, max_len, tgt_vocab_size):\n",
    "    enc.eval()\n",
    "    dec.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, hidden = enc(input_seq)\n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        outs = torch.zeros(max_len, batch_size, tgt_vocab_size, device=CUDA)\n",
    "        att_scores = torch.zeros(max_len, encoder_outputs.shape[0], batch_size, device=CUDA)\n",
    "        decoder_input = sos_token\n",
    "\n",
    "        for idx in range(max_len):\n",
    "            decoder_output, hidden, att_score = dec(decoder_input, encoder_outputs, hidden)\n",
    "            att_scores[idx] = att_score[-1]\n",
    "            outs[idx] = decoder_output[-1]\n",
    "            decoder_input = torch.argmax(outs[idx:idx+1], dim=2)\n",
    "        \n",
    "    return torch.argmax(outs, dim=2), att_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs, scores = translate(enc, dec, x[1, :, 0:3], y[1, 0:1, 0:3], 6, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[44, 78, 61],\n",
      "        [69, 73, 31],\n",
      "        [30, 81, 25],\n",
      "        [76, 82, 93],\n",
      "        [82, 10, 22],\n",
      "        [79, 75, 21]], device='cuda:0')\n",
      "tensor([[44, 78, 61],\n",
      "        [69, 73, 31],\n",
      "        [30, 81, 25],\n",
      "        [76, 82, 93],\n",
      "        [82, 10, 22],\n",
      "        [79, 75, 21]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(outs.squeeze())\n",
    "print(y[1, 1:, 0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 10, 3])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(scores[:, :, 0].cpu())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
